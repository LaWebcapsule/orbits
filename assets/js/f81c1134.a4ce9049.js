"use strict";(self.webpackChunkorbits_doc=self.webpackChunkorbits_doc||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"orchestrate-stack","metadata":{"permalink":"/blog/orchestrate-stack","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-09-26-orchestrate-a-stack-of-services.md","source":"@site/blog/2025-09-26-orchestrate-a-stack-of-services.md","title":"Orchestrating a stack of services across multiple environments","description":"In our previous blog post, we introduced the basics of orchestration and showed how to write a deployment workflow for a backend service.","date":"2025-09-26T00:00:00.000Z","tags":[{"inline":true,"label":"orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"node.js","permalink":"/blog/tags/node-js"},{"inline":true,"label":"workflow","permalink":"/blog/tags/workflow"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"}],"readingTime":5.01,"hasTruncateMarker":true,"authors":[{"name":"Lo\xefc D\xe9champs","title":"CTO @ Webcapsule","url":"https://github.com/ldechamps","page":{"permalink":"/blog/authors/loic"},"socials":{"linkedin":"https://www.linkedin.com/in/loicdechamps/","github":"https://github.com/ldechamps"},"imageURL":"/img/authors/loic.png","key":"loic"}],"frontMatter":{"slug":"orchestrate-stack","title":"Orchestrating a stack of services across multiple environments","authors":["loic"],"tags":["orchestration","node.js","workflow","orbits"]},"unlisted":false,"nextItem":{"title":"Write your CI/CD in TypeScript","permalink":"/blog/ci-cd-in-typescript"}},"content":"In our [previous blog post](./2025-08-05-orchestration-in-typescript.md), we introduced the basics of orchestration and showed how to write a deployment workflow for a backend service.\\nNow, let\u2019s take it further.\\nImagine our web agencies manage web services across multiple tenants : one cloud instance per client. The stack includes several services, such as frontend, authentication, and backend. And it must support multi-tenant deployment.\\nThis brings new challenges:\\n\\n- coordinating deployments across environments\\n- sharing common resources (like a cloud account, a VPC, a database...) between services in the stack\\n- handling failures and rollbacks\\n- keeping each tenant isolated yet manageable\\n  To address this, we need to go beyond simple workflows and start managing state, transitions, shared resources, and deployment strategies.\\n  Let\u2019s see how simple this becomes with Orbits.\\n\\n![orchestration](/img/blog/orchestration-2.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## From workflows to agents\\n\\nIn Orbits, a `Workflow` is a one-time execution: it runs, performs its actions, and then it\'s done. While this is useful, it\'s not enough when you want to manage stateful, reusable services across multiple environments or tenants.\\n\\nInstead, Orbits introduces the concept of a `Agent`.\\n\\nA `Agent` encapsulates both the identity of what you\u2019re deploying and the logic for how to install, update, or manage it. Agents can be reused, composed, and tracked.\\n\\n### Defining a BaseAgent\\n\\n#### Giving an identity to our services\\n\\nTo manage multiple services per tenant, such as frontend and backend, we start by defining a `BaseAgent`. This base class provides a common identity mechanism using the tenantId and a service-specific name. The `identity()` method uniquely identifies each agent instance, which allows Orbits to track, reconcile, and avoid duplicating shared agents.\\n\\n```ts\\nexport class BaseAgent extends Agent {\\n    IArgument: {\\n        tenantId: string;\\n    };\\n\\n    serviceName = \'base\';\\n\\n    identity() {\\n        return `${this.serviceName}-${this.argument.tenantId}`;\\n    }\\n}\\n```\\n\\n#### Sharing a common installation step\\n\\nOrbits ressources distinguish between the installation phase and the update phase. This allows precise control over what happens during first-time deployment versus subsequent updates.\\n\\nWe can implement shared setup, such as Git repository creation and cloud account provisioning, in the `defineInstall()` method of `BaseAgent`:\\n\\n```ts\\nexport class BaseAgent extends Agent {\\n    async defineInstall() {\\n        const createGit = new GitAgent().setArgument({\\n            name: this.serviceName,\\n        });\\n        const createAWS = new AWSAgent().setArgument({\\n            id: this.tenantId,\\n        });\\n\\n        await Promise.all([\\n            this.do(\'git-install\', createGit),\\n            this.do(\'aws-install\', createAWS),\\n        ]);\\n    }\\n}\\n```\\n\\nIn this setup:\\n\\n- GitAgent uses `serviceName`, so each service (frontend, backend) gets its own Git repository.\\n- AWSAgent uses `tenantId`, ensuring every services share the same cloud account for a given tenant : no duplicate account will be created.\\n\\n### Differentiating frontend and backend\\n\\nOnce the shared installation is abstracted, each service can implement its own logic tailored to its infrastructure and operational needs.\\nHere we modify the `update` step.\\n\\n#### Backend agent\\n\\n```ts\\nexport class BackendAgent extends BaseAgent {\\n    declare serviceName = \'backend\';\\n\\n    async defineUpdate() {\\n        // Step 1: Deploy Infrastructure-as-Code\\n        const deploymentOutput = await this.do(\\n            \'iac-deploy\',\\n            new BackCDKStack()\\n        );\\n\\n        // Step 2: Run SQL migrations inside the provisioned environment\\n        const migration = new RunSQLMigrations();\\n        migration.executor = new CloudExecutor(deploymentOutput.env);\\n        await this.do(\'sql-migrate\', migration);\\n    }\\n}\\n```\\n\\n#### Frontend agent\\n\\n```ts\\nexport class FrontendAgent extends BaseAgent {\\n    declare serviceName = \'frontend\';\\n\\n    async defineUpdate() {\\n        // Step 1: Deploy Infrastructure-as-Code\\n        const deploymentOutput = await this.do(\\n            \'iac-deploy\',\\n            new FrontCDKStack()\\n        );\\n\\n        // Step 2: clear caches inside the provisioned environment\\n        await this.do(\\n            \'clear-cdn-cache\',\\n            new CdnClearCacheAction().setArgument({\\n                cdnArn: deploymentOutput.cdnArn,\\n            })\\n        );\\n    }\\n}\\n```\\n\\nThis pattern offers:\\n\\n- clear separation of concerns between services\\n- reusability of common setup logic\\n- flexibility for specialized behavior per service\\n\\n### Scaling to multiple tenants\\n\\n#### Managing a stack\\n\\nNow let\u2019s define an application stack that orchestrates both frontend and backend services. This approach gives us control over the deployment order, error handling, and rollback strategy.\\nBelow is a schematic version of what this orchestration might look like:\\n\\n```ts\\nexport class MyStack extends Agent {\\n    async defineUpdate() {\\n        //choose a deployment strategy\\n        //here we first deploy the frontend and then the backend.\\n        //could have done this in parellel\\n        const backendAgent = new BackendAgent().setArgument(\\n            this.argument\\n        );\\n        const frontendAgent = new FrontendAgent().setArgument(\\n            this.argument\\n        );\\n        try {\\n            await this.do(\'update-backend\', backendAgent);\\n            await this.do(\'update-frontend\', frontendAgent);\\n        } catch (err) {\\n            //rollback to previous working commit\\n            await this.do(\\n                \'rollback-frontend\',\\n                frontendAgent.setCommand(\'rollback\')\\n            );\\n            await this.do(\\n                \'rollback-backend\',\\n                backendAgent.setCommand(\'rollback\')\\n            );\\n        }\\n    }\\n}\\n```\\n\\n:::tip\\nYou could easily parallelize both deployments using Promise.all if the order doesn\u2019t matter.\\n:::\\n\\n#### Managing multiple tenants\\n\\nTo scale across tenants, we define a Tenants agent that loops over each tenant and applies the stack. Failures are isolated and can be reported via Slack, email, or any other channel.\\n\\n```ts\\nexport class Tenants extends Agent {\\n    // you would likely fetch this from a database\\n    tenants = [\'clientA\', \'clientB\', \'clientC\'];\\n\\n    async defineUpdate() {\\n        const failed = [];\\n\\n        for (const tenantId of this.argument.tenants) {\\n            try {\\n                await this.do(\\n                    \'update-tenant\',\\n                    new MyStack().setArgument({ tenantId })\\n                );\\n            } catch (err) {\\n                failed.push({ tenantId, error: err });\\n                // Optionally notify immediately, or collect all and notify later\\n            }\\n        }\\n\\n        if (failed.length > 0) {\\n            await this.do(\\n                \'notify-failures\',\\n                new SlackNotification().setArgument({ failures: failed })\\n            );\\n        }\\n    }\\n}\\n```\\n\\n## What Orbits takes care of under the hood\\n\\nThis simple syntax addresses common pain points in managing cloud services under the hood:\\n\\n- avoiding duplication: when multiple executions of a agent run in parallel, Orbits ensures the same final state without recreating agents unnecessarily. The orchestrator intelligently determines what needs updating, skipping, or preserving.\\n- running scripts in different contexts : The concept of an executor provides a clean way to run specific actions within the right environment or context. Since infrastructure and scripts are managed together, it\u2019s easy to target the exact environment where a command should execute.\\n- safe error handling: Encapsulating orchestration logic in `Agent` enables rollback strategies when something fails mid-deployment.\\n- multi-Tenant scalability: The `Tenants` agent allows applying the same stack logic across many clients, while isolating failures and surfacing them clearly.\\n\\n## Possible enhancements\\n\\nThis example provides a basic overview of how we manage multi-tenant deployments. Looking ahead, there are several potential improvements that can be explored:\\n\\n- we could implement more complex rollback strategies\\n- we could implement drift detection via the `cycle` hook\\n- we could share some resources accross tenants with the same concept of `Agent`\\n\\n---\\n\\n_Wanna try Orbits? The complete documentation with samples and examples is available [here](https://orbits.do/documentation). The source code is available in the [github repository](https://github.com/LaWebcapsule/orbits). Give it a spin!_"},{"id":"ci-cd-in-typescript","metadata":{"permalink":"/blog/ci-cd-in-typescript","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-08-27-ci-cd-in-typescript.md","source":"@site/blog/2025-08-27-ci-cd-in-typescript.md","title":"Write your CI/CD in TypeScript","description":"If most CI/CD tools today are robust, the way we define scripts in them comes with a few drawbacks:","date":"2025-08-27T00:00:00.000Z","tags":[{"inline":true,"label":"orchestration","permalink":"/blog/tags/orchestration"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"},{"inline":false,"label":"CLI","permalink":"/blog/tags/cli","description":"Posts related to OrbiTS CLI"},{"inline":false,"label":"AWS CDK","permalink":"/blog/tags/aws-cdk","description":"Posts related to the AWS CDK"},{"inline":true,"label":"ci/cd","permalink":"/blog/tags/ci-cd"}],"readingTime":5.01,"hasTruncateMarker":true,"authors":[{"name":"Tom Marcuzzi","title":"Head of engineering @ Webcapsule","url":"https://linkedin.com/in/tom-marcuzzi","page":{"permalink":"/blog/authors/tom"},"socials":{"linkedin":"https://www.linkedin.com/in/tommarcuzzi/","github":"https://github.com/tommarcuzzi"},"imageURL":"/img/authors/tom.png","key":"tom"}],"frontMatter":{"slug":"ci-cd-in-typescript","title":"Write your CI/CD in TypeScript","authors":["tom"],"tags":["orchestration","orbits","cli","aws-cdk","ci/cd"]},"unlisted":false,"prevItem":{"title":"Orchestrating a stack of services across multiple environments","permalink":"/blog/orchestrate-stack"},"nextItem":{"title":"A deployment workflow with TypeScript","permalink":"/blog/orchestration-typescript"}},"content":"If most CI/CD tools today are robust, the way we define scripts in them comes with a few drawbacks:\\n\\n- they have strong vendor lock-ins;\\n- they are difficult to test and debug locally;\\n- they all use a different syntax in YAML, which is difficult to extend and compose.\\n  For all these reasons, when the person who wrote them is not around, it\u2019s not uncommon that teams don\u2019t know what scripts do. They rarely evolve and their maintenance is hard.\\n\\nUsing code and native Node.js modules to write CI/CD could solve all these problems and comes with a lot of benefits:\\n\\n- it\u2019s possible to debug locally. To avoid regressions, it\'s even possible to test the CI/CD with a normal testing framework;\\n- it offers better reusability across projects and greater composability;\\n- it uses code instead of configuration, making it easy to catch errors, manage retries, loops, and conditional logic;\\n- it integrates seamlessly with the rich Node.js ecosystem.\\n\\n![ci-cd](/img/blog/singe-ci-cd.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## Example: handle your CI/CD in Node.js with Orbits\\n\\nThis blog post will follow the [simple deployment pipeline sample](https://github.com/LaWebcapsule/orbits/tree/main/samples/simple-deployment-pipeline) available on the github repository of orbits.\\n\\nThis sample deploys an AWS Lambda that will respond to a GET request with this architecture:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   cloudfront   \u2502\u25c4\u2500\u2500\u25ba\u2502   api gateway  \u2502\u25c4\u2500\u2500\u25ba\u2502   lambda       \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nOur complete workflow is:\\n\\n1. Format, lint and test our Lambda code\\n2. Deploy it to AWS using CDK and the orbits CDK helper\\n3. Clear the CloudFront cache\\n4. Check the deployed endpoint\\n\\n### Prerequisites\\n\\nYou\'ll need:\\n\\n- Access to one AWS account\\n- Node.js and npm installed\\n- MongoDB instance for orbits state management\\n\\n### Project Setup\\n\\n```bash\\n# Clone the repository\\ngit clone https://github.com/LaWebcapsule/orbits.git\\ncd samples/simple-deployment-pipeline\\n\\n# Install dependencies\\nnpm install\\n\\n# Configure environment\\nexport AWS_REGION=you-aws-region\\nexport AWS_ACCOUNT=you-aws-account\\n\\n# Install the CLI either globally or in your project\\n## globally\\nnpm i @orbi-ts/cli -g\\n\\n## in your project\\nnpm i @orbi-ts/cli\\n\\n# define your mongo_url\\n## default is mongodb://localhost:27017/orbits\\nexport ORBITS_DB__MONGO__URL=your-mongo-url\\n```\\n\\n### Run the deployment workflow\\n\\nFrom peeking at `orbi.ts` we see that `DeployHelloWorkflow` takes two arguments:\\n\\n- `region`: the AWS region\\n- `account`: the AWS account\\n\\nSo running it is as easy as typing this command:\\n\\n```bash\\norbits-cli actions run -f src/orbits/orbi.ts --local-worker \\\\\\n  DeployHelloWorkflow \\\\\\n  region=$AWS_REGION \\\\\\n  account=$AWS_ACCOUNT\\n```\\n\\nHere is a video of the deployment:\\n<video controls width=\'100%\'>\\n\\n<source src=\'https://orbits-assets.s3.eu-west-3.amazonaws.com/public/videos/cli-run.mp4\'/>\\n</video>\\n<br/><br/>\\n\\nWe can get the result of the deploy action using the get method (provided its ID is `689de1b3fcb667fee45a4bfe`):\\n\\n```bash\\n\u279c orbits-cli actions get 689de1b3fcb667fee45a4bfe\\nID                       \u2506 ACTION REF     \u2506 STATE   \u2506 RESULT                                                                                                                                                             \u2506 LAST ACTIVITY \u2506 NEXT ACTIVITY \u2506 PARENT > REF\\n\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\u2508\\n689de1b3fcb667fee45a4bfe \u2506 LambdaAgent \u2506 SUCCESS \u2506 {\\"CfId\\":\\"E28NIDFX6OEEC6\\",\\"HelloAPIEndpointA3FBFD89\\":\\"https://fueo1zarcg.execute-api.eu-west-3.amazonaws.com/prod/\\",\\"CfDomainName\\":\\"d16q083cvq1ymk.cloudfront.net\\"} \u2506 \u2014             \u2506 in 7min 45s   \u2506 689de1b1fcb667fee45a4bc1 > deploy\\n```\\n\\nWith its ID, you can get the graphical view of an Action / Workflow at any moment:\\n\\n```bash\\norbits-cli actions watch <ACTION_ID>\\n```\\n\\nWith this in mind, you have a complete history of your deployment and can see precisely where it failed.\\n\\n### Debugging part of the workflow\\n\\nIn this section, we\u2019ll introduce a failure in the Code Quality workflow and see how it shows up during execution.\\n\\nFirst, here\u2019s how our deployment workflow is defined:\\n\\n```ts title=\\"src/orbits/orbi.ts\\"\\nimport { Workflow } from \'@orbi-ts/core\';\\nimport { CodeQualityWorkflow } from \'./code-quality\';\\nimport { InvalidateCacheAction } from \'./invalidate-cache\';\\nimport { LambdaAgent } from \'./lambda-agent\';\\nimport { VerifyLambdaDeploymentAction } from \'./verify\';\\n\\nexport class DeployHelloWorkflow extends Workflow {\\n    declare IArgument: Workflow[\'IArgument\'] & {\\n        region: string;\\n        account: string;\\n    };\\n\\n    async define() {\\n        await this.do(\'quality\', new CodeQualityWorkflow());\\n        const result = await this.do(\\n            \'deploy\',\\n            new LambdaAgent({\\n                region: this.argument.region,\\n                account: this.argument.account,\\n            })\\n        );\\n\\n        await this.do(\\n            \'invalidate cache\',\\n            new InvalidateCacheAction().setArgument({\\n                distributionId: result.CfId,\\n                env: { region: this.argument.region },\\n            })\\n        );\\n\\n        await this.do(\\n            \'verify\',\\n            new VerifyLambdaDeploymentAction().setArgument({\\n                endpoint: `https://${result.CfDomainName}`,\\n            })\\n        );\\n    }\\n}\\n```\\n\\nBecause we know the name of an action and its arguments, running it directly is very simple.\\n\\nLet\u2019s try running the _Code Quality_ workflow. Since the `DeployHelloWorkflow` action doesn\u2019t require arguments, we can run:\\n\\n```bash\\norbits-cli actions run CodeQualityWorkflow -f src/orbits/orbi.ts --local-worker\\n```\\n\\nWe get the following graphical view of the workflow \u2014 everything is green, no errors!\\n\\n![run results](/img/blog/cli/test-run.png)\\n\\nNow let\u2019s make the handler fail the tests. We\u2019ll modify the code as follows:\\n\\n```ts title=\\"src/handler/hello.ts\\"\\ntype HelloEvent = {\\n    queryStringParameters: {\\n        first_name?: string;\\n        last_name?: string;\\n    };\\n};\\n\\nexport const handler = async (\\n    event: HelloEvent\\n): Promise<{\\n    statusCode: number;\\n    body: string;\\n}> => {\\n    // const firstName = event.queryStringParameters.first_name;\\n    const firstName = \'Alice\';\\n    const lastName = event.queryStringParameters.last_name;\\n    const now = new Date();\\n    return {\\n        statusCode: 200,\\n        body:\\n            `Hello ${[firstName, lastName].filter(Boolean).join(\' \') || \'Guest\'}, ` +\\n            `time is ${now.getUTCHours()}:${now.getUTCMinutes()}:${now.getUTCSeconds()} (UTC)`,\\n    };\\n};\\n```\\n\\nWhen we re-run without exiting the process, the workflow fails and moves into the `ERROR` state. We can inspect the error in the logs, or view the result in the dedicated panel:\\n\\n![run fail](/img/blog/cli/test-run-fail.png)\\n\\nLet\u2019s fix the test by restoring the original line:\\n\\n```ts\\nconst firstName = event.queryStringParameters.first_name;\\n// const firstName = \'Alice\'; <-- remove this line\\n```\\n\\nNow, in another terminal, we can replay the test action by its ID:\\n\\n```bash\\norbits-cli actions replay $ACTION_ID\\n```\\n\\nOr replay the entire workflow starting from the test step:\\n\\n```bash\\norbits-cli actions replay $WORKFLOW_ID -p test\\n```\\n\\nThis time everything passes again \u2014 back to green \u2705.\\n\\nSee it in action:\\n<video controls width=\'100%\'>\\n\\n  <source src=\'https://orbits-assets.s3.eu-west-3.amazonaws.com/public/videos/cli-replay.mp4\'/>\\n</video>\\n<br/><br/>\\n\\n### Going further\\n\\n- You can now write and integrate CI/CD workflows directly into your own project.\\n- More than just workflows, orbits is especially useful when you want to share workflows across projects and tenants. Read our [blog series about orchestration](./2025-08-05-orchestration-in-typescript.md).\\n- As the project grows, we plan to add more helper functions to quickly build your CI/CD. Stay up to date by following the [github repository](https://github.com/LaWebcapsule/orbits).\\n\\n---\\n\\n_Wanna try it yourself? The complete example code and setup instructions are available in the [github repository](https://github.com/LaWebcapsule/orbits/tree/main/samples/simple-deployment-pipeline). Give it a spin!_"},{"id":"orchestration-typescript","metadata":{"permalink":"/blog/orchestration-typescript","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-08-05-orchestration-in-typescript.md","source":"@site/blog/2025-08-05-orchestration-in-typescript.md","title":"A deployment workflow with TypeScript","description":"In modern platform engineering, building a developer self-service portal isn\u2019t just about provisioning \u2014 it\u2019s about ensuring the entire golden path reliably completes, from infrastructure to runtime configuration.","date":"2025-08-05T00:00:00.000Z","tags":[{"inline":true,"label":"orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"self-adaptive platform","permalink":"/blog/tags/self-adaptive-platform"},{"inline":true,"label":"drift-detection","permalink":"/blog/tags/drift-detection"},{"inline":true,"label":"automation","permalink":"/blog/tags/automation"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"},{"inline":true,"label":"workflow","permalink":"/blog/tags/workflow"}],"readingTime":2.47,"hasTruncateMarker":true,"authors":[{"name":"Lo\xefc D\xe9champs","title":"CTO @ Webcapsule","url":"https://github.com/ldechamps","page":{"permalink":"/blog/authors/loic"},"socials":{"linkedin":"https://www.linkedin.com/in/loicdechamps/","github":"https://github.com/ldechamps"},"imageURL":"/img/authors/loic.png","key":"loic"}],"frontMatter":{"slug":"orchestration-typescript","title":"A deployment workflow with TypeScript","authors":["loic"],"tags":["orchestration","self-adaptive platform","drift-detection","automation","orbits","workflow"]},"unlisted":false,"prevItem":{"title":"Write your CI/CD in TypeScript","permalink":"/blog/ci-cd-in-typescript"},"nextItem":{"title":"Why orchestration matters?","permalink":"/blog/why-orchestration-matters"}},"content":"In modern platform engineering, building a developer self-service portal isn\u2019t just about provisioning \u2014 it\u2019s about ensuring the entire [golden path](https://www.redhat.com/en/topics/platform-engineering/golden-paths) reliably completes, from infrastructure to runtime configuration.\\nWhether you\'re spinning up environments for feature previews or onboarding a new client, orchestration is [the logic that holds everything together](https://platformengineering.org/blog/why-your-internal-developer-platform-needs-a-backend) \u2014 especially when things go wrong.\\nYour orchestrator should let you observe state transitions and trigger specific commands accordingly\u2014whether it\'s provisioning, reconciling drift, or handling failures.\\n\\n![workflow](/img/blog/workflow.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## Example: deploying a backend from scratch\\n\\nLet\u2019s walk through a typical use case for an agency or SaaS company: deploying a new backend environment for a client or project. This often involves:\\n\\n- Creating a dedicated cloud account\\n- Creating a Git repository\\n- Deploying infrastructure-as-code (e.g., CDK or Terraform)\\n- Running SQL migrations in the target environment\\n- Notifying the team of success or failure\\n\\nHere\u2019s how you would orchestrate that using Orbits:\\n\\n### A Simple declarative workflow in TypeScript\\n\\n```ts\\nexport class DeployBackend extends Workflow {\\n    async define() {\\n        try {\\n            // Step 1: Create Git and Cloud resources in parallel\\n            const createGit = new CreateGitRepo();\\n            const createAWS = new CreateAWSAccount();\\n\\n            await Promise.all([\\n                this.do(\'git-create\', createGit),\\n                this.do(\'aws-create\', createAWS),\\n            ]);\\n\\n            // Step 2: Deploy Infrastructure-as-Code\\n            const deploymentOutput = await this.do(\\n                \'iac-deploy\',\\n                new DeployCDKStack()\\n            );\\n\\n            // Step 3: Run SQL migrations inside the newly provisioned environment\\n            const migration = new RunSQLMigrations();\\n            migration.executor = new CloudExecutor(deploymentOutput.env);\\n            await this.do(\'sql-migrate\', migration);\\n        } catch (err) {\\n            // Step 4: Handle errors with a notification\\n            await this.do(\\n                \'notify-slack\',\\n                new SendSlackAlert().setArgument(err)\\n            );\\n        }\\n    }\\n}\\n```\\n\\n### Advantages\\n\\n#### Inheritance and code reuse\\n\\nWhen managing multiple services (e.g., backend, frontend, authentication), it\'s common to share infrastructure logic\u2014like creating a Git repository or provisioning a cloud account.\\n\\nOrbits makes this easy by allowing you to extract shared logic into a base class:\\n\\n```ts\\nexport class BaseWorkflow extends Workflow {\\n    defineCreation() {\\n        const createGit = new CreateGitRepo();\\n        const createAWS = new CreateAWSAccount();\\n\\n        await Promise.all([\\n            this.do(\'git-create\', createGit),\\n            this.do(\'aws-create\', createAWS),\\n        ]);\\n    }\\n}\\n```\\n\\nYou can then extend this base in specific workflows:\\n\\n```ts\\nexport class FrontendWorkflow extends BaseWorkflow {\\n    // Additional frontend-specific steps\\n}\\n```\\n\\nBy properly modeling shared resources, you can also ensure that different services (like frontend and backend) reuse the same AWS account rather than creating duplicates.\\n\\n#### TypeScript ecosystem\\n\\nSince Orbits is written in TypeScript, you can directly use SDKs from your providers (like the AWS SDK).\\nFor example, in order to create an AWS account, you can just call:\\n\\n```ts\\nconst client = new OrganizationsClient();\\nclient.send(\\n    new CreateAccountCommand({\\n        AccountName: name,\\n        Email: email,\\n    })\\n);\\n```\\n\\n#### Test on local\\n\\nAll the orchestrator run inside your node.js process.\\nAs a consequence, you can run and test your workflows locally, just like any other TypeScript code \u2014 enabling fast iteration and simplified debugging during development.\\n\\n### Going further\\n\\nWant to go further and orchestrate multiple tenants or environments? Check out our [next post](./2025-09-26-orchestrate-a-stack-of-services.md) on managing a fleet of stacks with Orbits."},{"id":"why-orchestration-matters","metadata":{"permalink":"/blog/why-orchestration-matters","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-07-30-why-orchestration-matters.md","source":"@site/blog/2025-07-30-why-orchestration-matters.md","title":"Why orchestration matters?","description":"While cloud services offer great flexibility in their usage and consumption, their growth has also led to an increase in the supply, with a multiplication of APIs, tools, and platforms to enhance, facilitate, and optimize access to cloud services. \\\\[1\\\\] This proliferation of offerings is one of the reasons that has led to the heterogeneity of cloud environments and the difficulty of their interoperability. \\\\[2\\\\]. It is now widely accepted that \u201ccloud resource management, traditionally handled by system administrators, must now be automated to be efficient, secure, and dynamic.\u201d \\\\[3\\\\]","date":"2025-07-30T00:00:00.000Z","tags":[{"inline":true,"label":"orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"self-adaptive platform","permalink":"/blog/tags/self-adaptive-platform"},{"inline":true,"label":"drift-detection","permalink":"/blog/tags/drift-detection"},{"inline":true,"label":"automation","permalink":"/blog/tags/automation"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"},{"inline":true,"label":"workflow","permalink":"/blog/tags/workflow"}],"readingTime":4.5,"hasTruncateMarker":true,"authors":[{"name":"Louis Dussarps","title":"CEO @ Webcapsule","url":"https://github.com/louisdussarps","page":{"permalink":"/blog/authors/louis"},"socials":{"linkedin":"https://www.linkedin.com/in/louisdussarps/","github":"https://github.com/louisdussarps"},"imageURL":"/img/authors/louis.png","key":"louis"}],"frontMatter":{"slug":"why-orchestration-matters","title":"Why orchestration matters?","authors":["louis"],"tags":["orchestration","self-adaptive platform","drift-detection","automation","orbits","workflow"]},"unlisted":false,"prevItem":{"title":"A deployment workflow with TypeScript","permalink":"/blog/orchestration-typescript"},"nextItem":{"title":"Write Node.js workflows to orchestrate microservices","permalink":"/blog/workflows-orchestrate-microservices"}},"content":"While cloud services offer great flexibility in their usage and consumption, their growth has also led to an increase in the supply, with a multiplication of APIs, tools, and platforms to enhance, facilitate, and optimize access to cloud services. \\\\[[1](https://www.researchgate.net/profile/Neha-Agrawal-4/publication/354149677_Autonomic_cloud_computing_based_management_and_security_solutions_State-of-the-art_challenges_and_opportunities/links/62c6bea051f08a717c149f44/Autonomic-cloud-computing-based-management-and-security-solutions-State-of-the-art-challenges-and-opportunities.pdf)\\\\] This proliferation of offerings is one of the reasons that has led to the heterogeneity of cloud environments and the difficulty of their interoperability. \\\\[[2](https://theses.hal.science/tel-02798770)\\\\]. It is now widely accepted that \u201ccloud resource management, traditionally handled by system administrators, must now be automated to be efficient, secure, and dynamic.\u201d \\\\[[3](https://radar.inria.fr/rapportsactivite/RA2023/ctrl-a/ctrl-a.pdf)\\\\]\\n\\nFrom this perspective, Ops teams and developers must be supported by complex engineering platforms called Internal Developer Platforms. These platforms must ensure requirements for quality of service, security, and cloud cost, while also allowing administrators access for audit, customization, and modification purposes.\\n\\n![orchestration](/img/blog/orchestration.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## Autonomic cloud computing\\n\\nTo address the issue of heterogeneity in cloud resources, a research field called autonomic cloud computing has decided to overturn the imperative programming perspective. While it is difficult to specify the state of each resource used, the desired outcome\u2014the target state of the system\u2014is often known. Essentially, this involves applying the principles of a thermostat to web infrastructures. The idea is to apply Control Theory results to software design, more precisely to cloud resource orchestration \\\\[[4](https://inria.hal.science/hal-01281063v1/document)\\\\].\\n\\nIn this paradigm, a resource is managed by controllers. For example, Kubernetes DevOps engineers are accustomed to [handling controllers](https://kubernetes.io/docs/concepts/architecture/controller/) and build their infrastructures by specifying desired states, such as indicating that a service node should always consume between 30% and 100% of its dedicated CPU.\\n\\nHowever, these controllers are only used within limited scopes. Indeed, autonomic computing (AC) creates complex systems, which slows down their generalization \\\\[[5](https://www.sei.cmu.edu/library/guide-to-implementing-devsecops-for-a-system-of-systems-in-highly-regulated-environments/)\\\\]. Moreover, mastering this paradigm by system engineers is a challenge for its adoption \\\\[[6](https://inria.hal.science/hal-01281063v1/document)\\\\].\\n\\nActions aimed at ensuring infrastructure commissioning, structuring incident response, or verifying application compliance with security policies are rarely subject today to feedback loops. The definition of transitions between configurations is then \u201cvery tedious and costly, which may consequently lead to error-prone dynamic behaviors\u201d \\\\[[7](https://hal.science/hal-01450517)\\\\].\\n\\n## The Role of operator knowledge in DevSecOps environments\\n\\nThis separation, however, comes from the DevSecOps approach itself. Embedded in a control paradigm, it is important for organizations to have an abstract understanding of all their components. Thus, implementation models used in highly regulated environments begin with the establishment of architectural diagrams and models \\\\[[8](https://kilthub.cmu.edu/articles/report/Using_Model-Based_Systems_Engineering_MBSE_to_Assure_a_DevSecOps_Pipeline_is_Sufficiently_Secure/22592884?file=40862315)\\\\]. In these models, the response to an event and the actions applied to the system are pipelines \\\\[[5](https://www.sei.cmu.edu/library/guide-to-implementing-devsecops-for-a-system-of-systems-in-highly-regulated-environments/)\\\\]. Deploying a new software version, building an artifact, or responding to a security incident are all encompassed under the concept of a pipeline or workflow.\\n\\nAs a consequence of this perspective, in the industry, all tools responsible for this DevSecOps part are workflow tools that themselves use [acyclic graphs](https://luigi.readthedocs.io/en/stable/tasks.html).\\n\\nSuch a design implicitly assumes that a human, an Ops engineer, supervises and can have full knowledge of the entire system. This thesis has proven difficult to maintain given the system\u2019s complexity but, within a socio-economic system, it helps maintain the chain of accountability. In this regard, a number of anti-patterns that appear in Continuous Integration (CI) construction stem from the implementers\u2019 lack of system knowledge. For example, CI anti-patterns often arise from the \u201cinadequate choice of hardware and software components \\\\[which\\\\] can make artifact builds slow and non-reproducible\u201d \\\\[[9](https://www.zora.uzh.ch/id/eprint/197036/)\\\\]. As mentioned earlier, resource management systems that rely on exact step specifications prove error-prone and suboptimal; they hinder the replicability of architectures.\\n\\n## The antinomy between dynamic adaptation and acyclic workflows\\n\\n- Autonomic cloud computing advocates the use of algorithms based on feedback loops to dynamically adapt to changes.\\n- Workflows responsible for orchestrating distributed environments, however, are designed as acyclic graphs, thereby preventing the incorporation of feedback loops and the specification of deliveries through desired state definitions.\\n  Yet today, \u201cthere is no cloud resource orchestration programming language to uniformly describe and combine resource descriptions.\u201d \\\\[[10](https://ieeexplore.ieee.org/document/7230217)\\\\]\\n\\n## Unlocking efficiency and security with autonomic cloud practices\\n\\nAs a consequence, a strategic application of autonomic computing (AC) across the entire application lifecycle\u2014including critical DevSecOps processes\u2014offers several key benefits:\\n\\n- Reduce error-prone deployments: a control system based on AC enables effective immediate rollbacks in case a bug is present in a release.\\n\\n- Increase system security: automatic detection of certain events, such as the release of a security patch, helps reduce the attack surface.\\n\\n- Simplify design for operators: with the right level of expressiveness, operators no longer need to know the entire system but only the desired state of their application.\\n\\nTo support these goals, Orbits provides a TypeScript framework designed for effortlessly creating state machines and feedback loops, empowering developers and operators to effectively manage the lifecycle of cloud stacks."},{"id":"workflows-orchestrate-microservices","metadata":{"permalink":"/blog/workflows-orchestrate-microservices","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-07-22-orchestate-microservices.md","source":"@site/blog/2025-07-22-orchestate-microservices.md","title":"Write Node.js workflows to orchestrate microservices","description":"Databases follow the principle of transactions \u2014 a set of changes that must either all succeed or all fail. But when an application interacts with multiple databases or connects to various APIs (as is the case for most applications today), the guarantees of ACID are lost. Workflows, state machines, and the saga pattern help achieve a similar level of reliability, often at the cost of more complex code. Here, we introduce a Node.js framework that makes it easy to write such workflows in TypeScript.","date":"2025-07-22T00:00:00.000Z","tags":[{"inline":true,"label":"orchestration","permalink":"/blog/tags/orchestration"},{"inline":true,"label":"microservices","permalink":"/blog/tags/microservices"},{"inline":true,"label":"saga-pattern","permalink":"/blog/tags/saga-pattern"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"},{"inline":true,"label":"workflow","permalink":"/blog/tags/workflow"}],"readingTime":5.64,"hasTruncateMarker":true,"authors":[{"name":"Lo\xefc D\xe9champs","title":"CTO @ Webcapsule","url":"https://github.com/ldechamps","page":{"permalink":"/blog/authors/loic"},"socials":{"linkedin":"https://www.linkedin.com/in/loicdechamps/","github":"https://github.com/ldechamps"},"imageURL":"/img/authors/loic.png","key":"loic"},{"name":"Louis Dussarps","title":"CEO @ Webcapsule","url":"https://github.com/louisdussarps","page":{"permalink":"/blog/authors/louis"},"socials":{"linkedin":"https://www.linkedin.com/in/louisdussarps/","github":"https://github.com/louisdussarps"},"imageURL":"/img/authors/louis.png","key":"louis"}],"frontMatter":{"slug":"workflows-orchestrate-microservices","title":"Write Node.js workflows to orchestrate microservices","authors":["loic","louis"],"tags":["orchestration","microservices","saga-pattern","orbits","workflow"]},"unlisted":false,"prevItem":{"title":"Why orchestration matters?","permalink":"/blog/why-orchestration-matters"},"nextItem":{"title":"Automate deployments of cdk8s template","permalink":"/blog/programmable-cdk8s-deployment"}},"content":"Databases follow the principle of transactions \u2014 a set of changes that must either all succeed or all fail. But when an application interacts with multiple databases or connects to various APIs (as is the case for most applications today), the guarantees of ACID are lost. Workflows, state machines, and the saga pattern help achieve a similar level of reliability, often at the cost of more complex code. Here, we introduce a **Node.js** framework that makes it easy to write such workflows in TypeScript.\\n\\nTo follow along, you can find the full source code in [Orbit\u2019s GitHub repository](https://github.com/LaWebcapsule/orbits/tree/main/samples/orchestrate-lambda).\\n\\n![lightweight temporal alternative](/img/blog/lightweight-temporal.png)\\n\\n\x3c!-- truncate --\x3e\\n\\n## Why explicitly orchestrate workflows?\\n\\nLet\'s take a common use case in a business application: **managing a stock trading transaction**.\\n\\nHere are the typical steps:\\n\\n1. Check the price of a stock\\n2. Generate a buy or sell recommendation\\n3. Execute the recommended action\\n\\nOn the surface, these are simple asynchronous calls that could be chained in a function:\\n\\n```ts\\nasync function trade() {\\n    const stockPrice = await checkPrice();\\n    const recommendation = await generateRecommendation(stockPrice);\\n    return recommendation === \'buy\'\\n        ? await buyStock(stockPrice)\\n        : await sellStock(stockPrice);\\n}\\n```\\n\\nBut in reality, problems accumulate:\\n\\n- What to do if a third-party service fails?\\n- What if a network error occurs?\\n- If the Node.js process is interrupted, the trade stops halfway, with no memory of the ongoing buy/sell operation.\\n\\nThese issues, far from being theoretical, can have financial consequences. For example, a buy or sell action that is forgotten or left halfway through can lead to losses for the company.\\n\\n## The Saga Orchestration Pattern\\n\\nThe [**Saga Orchestration Pattern**](https://microservices.io/patterns/data/saga.html) effectively addresses these challenges. By centralizing workflow management in an orchestrator, this pattern mimics the transaction principle of a database. It allows a series of atomic actions, executed sequentially and under control, to be linked together into a global transaction.\\n\\nThe orchestrator:\\n\\n- Explicitly manages state transitions between each step;\\n- Persists workflow state to ensure recovery after crashes;\\n- Can replay actions in case of transient failure;\\n- Provides detailed traceability through clear naming of each step.\\n\\nThus, the Saga Orchestration pattern not only guarantees resilience and consistency of operations but also facilitates maintenance, monitoring, and evolution of complex workflows in a distributed environment.\\n\\n## Use Case\\n\\nIn this blog post, we revisit the example of orchestrating a banking transaction. This canonical example was provided by [AWS Step Functions](https://docs.aws.amazon.com/step-functions/latest/dg/sample-lambda-orchestration.html) and [Temporal](https://temporal.io/blog/temporal-replaces-state-machines-for-distributed-applications). Readers can refer to these articles to compare the syntax and ease of implementation offered by each tool.\\n\\n## The Implementation\\n\\nOrbits proposes writing workflows in a structured and declarative manner.\\nYou can explore and experiment with the full source code of the example described in this blog post in [Orbit\u2019s GitHub repository](https://github.com/LaWebcapsule/orbits/tree/main/samples/orchestrate-lambda).  \\nHere\'s the concrete example:\\n\\n```ts title=\\"src/orbits/workflows/trading.ts\\" wordWrap=true\\nexport class TradingWorkflow extends Workflow {\\n    declare IResult: StockTransaction;\\n\\n    async define() {\\n        const checkPrice = await this.do(\\n            \'check-price\',\\n            new CheckStockPriceAction()\\n        );\\n        const stockPrice = checkPrice.stockPrice;\\n\\n        const buyOrSell = await this.do(\\n            \'recommendation\',\\n            new GenerateBuySellRecommendationAction().setArgument({\\n                price: stockPrice.stock_price,\\n            })\\n        );\\n\\n        if (buyOrSell.buyOrSellRecommendation === \'sell\') {\\n            const sell = await this.do(\\n                \'sell\',\\n                new SellStockAction().setArgument({\\n                    price: stockPrice.stock_price,\\n                })\\n            );\\n            return sell.stockData;\\n        } else {\\n            const buy = await this.do(\\n                \'buy\',\\n                new BuyStockAction().setArgument({\\n                    price: stockPrice.stock_price,\\n                })\\n            );\\n            return buy.stockData;\\n        }\\n    }\\n}\\n```\\n\\nThis central workflow orchestrates each step by calling autonomous **Actions**, while maintaining branching logic and intermediate states.\\n\\n- **Explicit orchestration**: The Orbits engine manages calls, errors, retries, and state persistence\\n- **Atomic actions**: Each business step is an independent and testable action\\n- **Conditional branching**: The workflow flow can diverge based on data (buy or sell). It does not differ from standard TypeScript code.\\n- **Extensibility**: We can easily add steps, compensation logic, monitoring\\n- **Resilience**: Handles crash recovery, workflow state, and observability\\n\\nEach step is defined as an **Orbits Action**.\\n\\nHere\'s the implementation of the buy action:\\n\\n```ts\\nexport class BuyStockAction extends Action {\\n    async main() {\\n        const response = await fetch(API_ADDRESS + \'buyStock\', {\\n            method: \'POST\',\\n            headers: { \'Content-Type\': \'application/json\' },\\n            body: JSON.stringify({ stock_price: this.argument.price }),\\n        });\\n        this.result.stockData = await response.json();\\n        return ActionState.SUCCESS;\\n    }\\n}\\n```\\n\\nThis action:\\n\\n- Takes a **typed input** (price)\\n- Calls a remote API in an encapsulated manner\\n- **Returns a state - ActionState.SUCCESS**, ready to be recorded and resumed\\n- Handles **errors by default via a state - ActionState.ERROR**\\n\\nThis structuring makes the action not only **easy to test in isolation** but also **reusable in different workflows**, while simplifying its instrumentation for monitoring or debugging.\\n\\n## Workflow Visualization\\n\\nHere\'s a schematic representation of the orchestrated process:\\n\\n```mermaid\\nflowchart TD\\n    Start[\\"Start\\"] --\x3e CheckPrice[\\"CheckStockPrice\\"]\\n    CheckPrice --\x3e GenerateRec[\\"GenerateRecommendation\\"]\\n    GenerateRec --\x3e Decision{\\"Buy or Sell?\\"}\\n    Decision --\x3e|Buy| BuyStock[\\"BuyStock\\"]\\n    Decision --\x3e|Sell| SellStock[\\"SellStock\\"]\\n    BuyStock --\x3e End[\\"End\\"]\\n    SellStock --\x3e End\\n```\\n\\n## Benefits Summary\\n\\nAdopting Orbits offers:\\n\\n**Standard TypeScript**\\n\\nOrbits is a standard TypeScript framework. You write promises and asynchronous functions just like you would anywhere else.\\n\\n**Clear separation of responsibilities**\\n\\n- **Workflow** = orchestration\\n- **Action** = unit business logic\\n\\n**Flexibility & Scalability**\\n\\n- We can modify the flow without touching business components\\n- Actions are reusable in multiple workflows\\n\\n**Resilience and recovery**\\n\\n- Orbits manages state persistence\\n- Automatic recovery from the last valid point\\n\\n**Native observability**\\n\\n- Each action is traceable, named, monitorable\\n\\n## Going further\\n\\n### Using lambdas async invocations\\n\\nFor the sake of hypothesis, let\u2019s assume our Lambda function runs for an extended period of time (which is not the case here). In such scenarios, there\u2019s a high chance that the initial HTTP call triggering the Lambda might fail unexpectedly\u2014due to a network issue or timeout, for example.\\n\\nTo prevent such failures from disrupting the overall workflow, you can configure retry policies.\\n\\nOrbits also supports asynchronous APIs and allows you to track execution status over time. When dealing with long-running Lambda functions, an Orbits action can return with an `ActionState.IN_PROGRESS`, and then delegate the follow-up logic to the `watcher()` [method](/documentation/core-concepts/action), which periodically checks the progress of the async process.\\n\\nThis approach requires a bit of additional setup, as you\u2019ll need to interact with the AWS Lambda API to track the specific invocation\u2019s result.\\n\\nWe\u2019ll cover how Orbits makes it easy to manage long-running processes in a dedicated blog post soon.\\n\\n### Using agents to manage concurrency\\n\\nIn our example, if we trigger the same order twice, it will be processed twice\u2014this isn\u2019t always the desired behavior.\\nOrbits provides an opinionated way to handle concurrency through a concept called agents. [Agents](/documentation/core-concepts/agent) allow you to control and limit the execution of actions to prevent unintended duplication.\\n\\n## Conclusion\\n\\nWith the simplicity of **Orbits in Node.js**, we can build systems that are reliable, readable, and maintainable, without changing your coding practices.\\n\\nFor your critical processes \u2014 e-commerce, finance, logistics, etc. \u2014 **adopting such an approach will significantly reduce your bug rate and inconsistencies**.\\n\\n---\\n\\n_Learn more about Orbits and its capabilities in our [documentation](/documentation/quickstart)._"},{"id":"programmable-cdk8s-deployment","metadata":{"permalink":"/blog/programmable-cdk8s-deployment","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-07-11-cdk8s-deployment.md","source":"@site/blog/2025-07-11-cdk8s-deployment.md","title":"Automate deployments of cdk8s template","description":"Cdk8s is a great tool to write your Kubernetes IaC templates using standard programming languages. But unlike the AWS cdk, which is tightly integrated with CloudFormation to manage stack deployment, cdk8s has no native deployment mechanism.","date":"2025-07-11T00:00:00.000Z","tags":[{"inline":false,"label":"CDK8S","permalink":"/blog/tags/cdk8s","description":"Posts related to CDK8S"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"},{"inline":false,"label":"Model-driven orchestration","permalink":"/blog/tags/model-driven-orchestration"}],"readingTime":5.3,"hasTruncateMarker":true,"authors":[{"name":"Tom Marcuzzi","title":"Head of engineering @ Webcapsule","url":"https://linkedin.com/in/tom-marcuzzi","page":{"permalink":"/blog/authors/tom"},"socials":{"linkedin":"https://www.linkedin.com/in/tommarcuzzi/","github":"https://github.com/tommarcuzzi"},"imageURL":"/img/authors/tom.png","key":"tom"},{"name":"Louis Dussarps","title":"CEO @ Webcapsule","url":"https://github.com/louisdussarps","page":{"permalink":"/blog/authors/louis"},"socials":{"linkedin":"https://www.linkedin.com/in/louisdussarps/","github":"https://github.com/louisdussarps"},"imageURL":"/img/authors/louis.png","key":"louis"}],"frontMatter":{"slug":"programmable-cdk8s-deployment","title":"Automate deployments of cdk8s template","authors":["tom","louis"],"tags":["cdk8s","orbits","model-driven orchestration"]},"unlisted":false,"prevItem":{"title":"Write Node.js workflows to orchestrate microservices","permalink":"/blog/workflows-orchestrate-microservices"},"nextItem":{"title":"Solving cross-account resources for AWS CDK","permalink":"/blog/cross-account-cdk"}},"content":"[Cdk8s](https://cdk8s.io/) is a great tool to write your Kubernetes IaC templates using standard programming languages. But unlike the [AWS cdk](https://aws.amazon.com/fr/cdk/), which is tightly integrated with CloudFormation to manage stack deployment, cdk8s has no native deployment mechanism.\\n\\nBy default, it allows you to synthesize manifests and deploy them using `kubectl apply`, or optionally through [Helm](https://helm.sh/). While both approaches can work, they often fall short for more advanced use cases \u2014 for example, when you want to programmatically chain deployments, export values from the chart, or implement a custom rollback and prune strategy.\\n\\nIn this blog post, we\u2019ll explain how we built a model-driven orchestrator for cdk8s using Orbits \u2014 a lightweight framework for orchestrating cloud resources and workflows. We\u2019ll show how you can use it, adapt it to your own needs, or even build your own orchestrator based on the same principles. If Orbits fits your use case, you can directly reuse what we\u2019ve built.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Need for cdk8s orchestration\\n\\nThere is no built-in way to programmatically and reliably deploy a cdk8s stack \u2014 especially outside of the AWS ecosystem.\\n\\nThe current options are:\\n\\n- Synthesize the stack and apply it with `kubectl apply`\\n- Deploy the stack as a Helm chart\\n\\nBut both of these have shortcomings:\\n\\n- They are not easily orchestrated programmatically;\\n- Helm has known limitations when integrating with cdk8s;\\n- There\u2019s no native support for retries, failover, or rollback;\\n- There is no built-in mechanism to chain the deployment of multiple charts, especially if some charts are on one kube cluster and other on another kube ;cluster\\n- Helm\u2019s rollback model didn\u2019t align with our platform needs.\\n\\nIn our case \u2014 building internal platforms for highly regulated environments \u2014 we needed more control. Our deployment flow had to:\\n\\n- Configure cloud provider resources via API calls;\\n- Deploy multiple charts programmatically in a precise order;\\n- Use the results of deployments (like IPs or service names) to configure other infrastructure components.\\n\\nGiven these needs, existing options were simply not enough.\\nWhat we were looking for resembled the CloudFormation model:\\n\\n- Attempt a deployment;\\n- Rollback to the previous state on failure;\\n- On success, prune obsolete resources;\\n- Output values that could be reused in subsequent steps.\\n\\nAdditionally, we needed:\\n\\n- Safe concurrent executions, to allow multiple deployments at the same time without conflict;\\n- Built-in retry policies for transient failures.\\n\\nThese requirements led us to build a dedicated orchestrator for cdk8s using Orbits \u2014 a model-driven orchestration engine designed for reliability and composability.\\n\\n## Final result\\n\\nThe result is an Orbits agent that manages your cdk8s deployment.\\nYou can read the [orbits documentation](/documentation/helper/integrations/cdk8s-agent) on how to use it.\\n\\n- You can use it by extending the base class:\\n\\n```ts\\nexport class BasicAgent extends Cdk8sAgent {\\n    StackConstructor = BasicChart;\\n}\\n```\\n\\n- Or dynamically assign a custom stack generation method:\\n\\n```ts\\nconst myCdk8sAgent = new Cdk8sAgent();\\nmyCdk8sAgent.generateStack = () => {\\n    return new cdk8s.Chart(myCdk8sAgent.app, \'empty-chart\');\\n};\\n\\nawait this.do(\'update-stack\', { dynamicAction: myCdk8sAgent });\\n```\\n\\n:::info Outputs\\nYou can export outputs, which allows you to chain charts or propagate values (like an IP address for DNS updates)\\n\\n```ts\\nasync setOutput() {\\n    const stack = await this.generateStack();\\n    const apiServiceInfo = await this.kubeApi.coreApi.readNamespacedService({\\n        name: stack.loadBalancerService.name,\\n        namespace: stack.loadBalancerService.metadata.namespace || \'default\',\\n    });\\n    return apiServiceInfo.status.loadBalancer.ingress[0].ip;\\n}\\n```\\n\\n:::\\n\\n:::info Concurrency\\nConcurrency is also managed by Orbits. If a deployment is already running, concurrent executions will be serialized to prevent state corruption\\n\\n```ts\\n// somewhere\\nthis.do(\'deploy\', new MyBasicChartAgent());\\n// elsewhere\\nthis.do(\'deploy\', new MyBasicChartAgent());\\n```\\n\\nThe two deployments will [coalesce](/documentation/core-concepts/agent#convergent-execution-coalescing).\\n:::\\n\\n:::info Crash-proof\\nOrbits is [crash-proof](/documentation/quickstart#workflow-a-chain-of-actions).\\nIf a crash occurs mid-deployment, Orbits will resume from the same step on restart.\\n:::\\n\\n## Implementation\\n\\nFrom a cdk8s chart, we want to:\\n\\n- Deploy the chart reliably\\n- Retry on failure\\n- Rollback to the previous state if necessary\\n- Prune obsolete resources\\n\\n### The orbits Cdk8s agents\\n\\nIn Orbits, [agents](/documentation/core-concepts/agents) are stateful units that define hooks like defineUpdate.\\nFor the deployment of a cdk8s chart, we only need the `update` hook.\\nThe high-level flow of the agent implementation is as follows:\\n\\n```ts\\nexport class Cdk8sAgent {\\n    async defineUpdate() {\\n        try {\\n            await this.do(\\"deploy\\", ...);\\n        } catch (err) {\\n            this.bag.rollBackNeeded = true;\\n            await this.do(\\"rollback\\", ...);\\n        } finally {\\n            await this.do(\\"prune\\", ...);\\n        }\\n\\n        if (!this.bag.rollBackNeeded) {\\n            await this.do(\\"storeNewChart\\", ...);\\n        }\\n    }\\n}\\n```\\n\\n```mermaid\\nflowchart TD\\n    Start[\\"Start\\"] --\x3e Deploy[\\"Deploy\\"]\\n    Deploy -- Success --\x3e FinallyPrune[\\"Prune\\"]\\n    Deploy -- Error --\x3e SetRollback[\\"Rollback\\"]\\n    SetRollback --\x3e FinallyPrune\\n    FinallyPrune --\x3e CheckRollbackFlag[\\"Deploy was successful?\\"]\\n    CheckRollbackFlag -- Yes --\x3e Store[\\"Store new chart\\"]\\n    Store --\x3e End[\\"End\\"]\\n    CheckRollbackFlag -- No --\x3e End\\n\\n    CheckRollbackFlag@{ shape: rounded}\\n```\\n\\nThe complete implementation is available [here on github](https://github.com/LaWebcapsule/orbits/blob/main/helpers/src/standards-agent/cdk8s/cdk8s-agent.ts)\\n\\n#### Deploying the chart\\n\\nThere are multiple ways to deploy a stack, but we chose `kubectl apply` because it updates only the resources that changed. That means kubectl is required in the environment running the deployment.\\n\\n#### Ensuring the deployment is successful\\n\\nWe don\u2019t just fire and forget. We verify that critical resources are ready:\\n\\n- All Deployments reach a ready state;\\n- Certificates (e.g., from cert-manager) are marked as ready.\\n  This check helps us ensure the cluster is in a stable and usable state before moving forward.\\n\\n#### Storing the latest chart\\n\\nWe store the chart contents in a Kubernetes Secret. The secret\u2019s name is generated based on the stack name:\\n\\n```ts\\nprivate genSecretName(): string {\\n        return `orbits.deployment.${this.argument.stackName}`;\\n}\\n```\\n\\nThis allows the system to compare the current state with the previous one during rollback or pruning.\\n\\n#### Pruning unused resources\\n\\nPruning depends on whether the deployment succeeded:\\n\\n- On success, we prune old resources;\\n- On failure, we prune newly created resources.\\n\\nWe compare the list of objects in the stored stack with the current state and remove the unneeded ones.\\nWe make sure to never delete:\\n\\n- Namespaces\\n- PersistentVolumeClaims\\n\\n### Key Benefits\\n\\n- CloudFormation-like rollback for Cdk8s chart\\n- Crash-safe and retryable deployments\\n- Safe concurrent operations\\n- Outputs and dependency chaining support\\n- Multi-tenants deployment support\\n\\n## Looking Forward\\n\\nOur orchestrator provides a robust and flexible foundation for managing cdk8s deployments in production. While it already solves some pain points, we plan to improve:\\n\\n- Improved diff tools to preview changes before applying them\\n- Extended tracking and monitoring of additional Kubernetes resources\\n  Additionally, the agent offers a promising starting point for implementing drift detection, but that topic will be covered in a future post.\\n\\n---\\n\\n_The source code of the CDk8SAgent is available here: [https://github.com/LaWebcapsule/orbits/blob/main/helpers/src/standards-agent/cdk8s/cdk8s-agent.ts](https://github.com/LaWebcapsule/orbits/blob/main/helpers/src/standards-agent/cdk8s/cdk8s-agent.ts)_"},{"id":"cross-account-cdk","metadata":{"permalink":"/blog/cross-account-cdk","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-06-25-cross-account-cdk.md","source":"@site/blog/2025-06-25-cross-account-cdk.md","title":"Solving cross-account resources for AWS CDK","description":"If you\'ve ever tried to build a multi-account AWS architecture using CDK or CloudFormation, you\'ve probably hit the same frustrating wall: cross-account resource references don\'t work without manual coordination and hardcoded values. What should be a simple task\u2014like reading a parameter from Account A in a Lambda function deployed to Account B\u2014becomes a tedious manual process. This behaviour is already documented and while AWS also documents workarounds, there\u2019s no indication that this is going to change anytime soon. However, these approaches don\'t scale when you have multiple services and resources spanning different accounts across your organization.","date":"2025-06-25T00:00:00.000Z","tags":[{"inline":false,"label":"AWS CDK","permalink":"/blog/tags/aws-cdk","description":"Posts related to the AWS CDK"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"}],"readingTime":6.81,"hasTruncateMarker":true,"authors":[{"name":"Louis Dussarps","title":"CEO @ Webcapsule","url":"https://github.com/louisdussarps","page":{"permalink":"/blog/authors/louis"},"socials":{"linkedin":"https://www.linkedin.com/in/louisdussarps/","github":"https://github.com/louisdussarps"},"imageURL":"/img/authors/louis.png","key":"louis"}],"frontMatter":{"slug":"cross-account-cdk","title":"Solving cross-account resources for AWS CDK","authors":["louis"],"tags":["aws-cdk","orbits"]},"unlisted":false,"prevItem":{"title":"Automate deployments of cdk8s template","permalink":"/blog/programmable-cdk8s-deployment"},"nextItem":{"title":"Infra is code","permalink":"/blog/manifesto"}},"content":"If you\'ve ever tried to build a multi-account AWS architecture using CDK or CloudFormation, you\'ve probably hit the same frustrating wall: cross-account resource references don\'t work without manual coordination and hardcoded values. What should be a simple task\u2014like reading a parameter from Account A in a Lambda function deployed to Account B\u2014becomes a tedious manual process. This behaviour is already [documented](https://www.luminis.eu/blog/cross-account-aws-resource-access-with-aws-cdk/) and while AWS also documents [workarounds](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/walkthrough-crossstackref.html), there\u2019s no indication that this is going to change anytime soon. However, these approaches don\'t scale when you have multiple services and resources spanning different accounts across your organization.\\n\\nThis post walks through a practical example that demonstrates both the problem and a solution using orbits, a tool designed to seamless orchestrate all of your IaC with code.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Cross-Account Problem\\n\\nAWS CDK and CloudFormation have a limitation: stacks cannot directly reference resources from other AWS accounts. This creates friction for common architectural patterns like:\\n\\n- Sharing Docker images between development and production accounts\\n- Accessing centralized secrets from distributed applications\\n- Setting up VPC peering connections\\n- Managing cross-account S3 bucket permissions\\n- Distributing Lambda layers across organizational boundaries\\n\\nHere\'s what this limitation looks like in practice:\\n\\n```ts\\nconst app = new cdk.App();\\n\\nconst paramA = new ParamStack(app, \'stack-A\', {\\n    env: { account: \'account-A\' },\\n});\\n\\nconst lambdaB = new LambdaStack(app, \'stack-B\', {\\n    parameterArn: paramA.parameter.arn, // \u274c This fails at synthesis time\\n    env: { account: \'account-B\' },\\n});\\n```\\n\\nThe traditional workaround involves manual steps: extracting ARNs, hardcoding values, coordinating resource policies, and deploying in specific sequences. This breaks the declarative nature of infrastructure-as-code and makes architectures brittle.\\n\\n## A Real-World Example\\n\\nHere\'s an \\"hello-world\\" scenario to illustrate the problem: deploying an AWS Systems Manager parameter in Account A and reading it from a Lambda function in Account B. While the \\"cross-account sharing\\" feature for AWS SSM parameter could be used, this simple use case illustrates the broader challenge perfectly.\\n\\n### The Traditional CDK Approach (Doesn\'t scale)\\n\\nWith standard CDK, you\'d need to:\\n\\n1. Deploy the parameter stack in Account A\\n2. Manually extract the parameter ARN\\n3. Hardcode the ARN into your Lambda stack for Account B\\n4. Manually configure cross-account IAM policies\\n5. Deploy the Lambda stack in Account B\\n6. Hope nothing changes, because updates require repeating this process\\n\\n### The Orchestration Solution with orbits\\n\\nWith orbits, the same architecture becomes straightforward:\\n\\n```ts\\nconst paramOutput = await this.do(\'updateParam\', new ParamAgent());\\n\\nawait this.do(\\n    \'updateLambda\',\\n    new LambdaAgent().setArgument({\\n        stackProps: {\\n            parameterArn: paramOutput.parameterArn, // \u2705 Direct cross-account reference\\n            env: { account: this.argument.accountB.id },\\n        },\\n    })\\n);\\n```\\n\\nThe key difference? Orbits handles the cross-account coordination automatically, allowing you to reference resources naturally regardless of which account they live in.\\n\\n## Hands-On: Building the Example\\n\\nThe following section walks through building this cross-account parameter example step by step.\\n\\n### Prerequisites\\n\\nYou\'ll need:\\n\\n- Access to two AWS accounts with CloudFormation deployment permissions\\n- Node.js and npm installed\\n- MongoDB instance for orbits state management\\n\\n### Project Setup\\n\\n```bash\\n# Clone the repository\\ngit clone <repository-url>\\ncd cross-account-example\\n\\n# Install dependencies\\nnpm install\\n\\n# Configure environment\\ncp .base.env .env\\n# Edit .env with your account details\\nvi .env\\n```\\n\\n### Project structure\\n\\n```bash\\n\u251c\u2500\u2500 src/\\n\u2502   \u251c\u2500\u2500 orbits/\\n\u2502   \u2502   \u251c\u2500\u2500 orbi.ts # Main orchestration script\\n\u2502   \u2502   \u251c\u2500\u2500 lambda-agent.ts # lambda agent definition\\n\u2502   \u2502   \u251c\u2500\u2500 param-agent.ts # Param agent definition\\n\u2502   \u2502   \u2514\u2500\u2500 hello-agent.ts # Hello agent definition: the agent that make the junction between param and lambda\\n\u2502   \u2514\u2500\u2500 cdk/              # CDK stack definitions\\n\u2502       \u251c\u2500\u2500 lambda.ts # lambda CDK stack\\n\u2502       \u2514\u2500\u2500 param.ts # Param CDK stack\\n\u251c\u2500\u2500 .base.env                # Environment template\\n\u251c\u2500\u2500 .env                     # Your environment variables (git-ignored)\\n\u251c\u2500\u2500 package.json\\n\u2514\u2500\u2500 README.md\\n```\\n\\n### The Agent Definitions\\n\\n#### Lambda and Param CDK Stack\\n\\nWe focus on two stack `LambdaStack` and `ParameterStoreStack`\\n[link to the stack]\\n\\n##### Lambda stack\\n\\nA lambda that will display the value of the parameter passed in parameter if it can access it.\\n\\n#### Parameter stack\\n\\nA parameter store that stores an \\"hello-world\\" value.\\n\\n#### Encapsulate the stacks in a agent definition.\\n\\nHere\'s what a CDK agent definitions look like:\\n\\n**Lambda Agent (lambda-agent.ts):**\\n\\n```ts title=\\"src/orbits/lambda-agent.ts\\"\\nexport class LambdaAgent extends CdkStackAgent {\\n    StackConstructor = LambdaStack;\\n\\n    declare IOutput: {\\n        roleArn: string;\\n    };\\n}\\n```\\n\\nLet\'s go line by line.\\n\\n- `StackConstructor = LambdaStack`: this tells the orchestrator that `LambdaAgent` will use the `LambdaStack` class constructor to define and manage its infrastructure.\\n-\\n\\n```ts\\ndeclare IOutput: {\\n    \\"roleArn\\": string\\n}\\n```\\n\\nThe CloudFormation stack for the Lambda function exports a single output: \\"roleArn\\", which is the ARN of the Lambda\'s execution role.\\nThe IOutput declaration is used for type safety\u2014it informs the developer that this agent will expose an output matching that structure.\\n\\n:::info\\nIf not already done, the CDK environment will be automatically bootstrapped by the CDKAgent\u2014no other step is required, the full lifecycle of your agent is managed.\\n:::\\n\\n#### Write a proxy agent to orchestrate both lambda and param deployment\\n\\nWe could choose different orchestrations strategies.\\nHere we choose to have a proxy agents that deploy both the `Param` and the `Lambda` stack and that synchronize the use of both in coordination.\\n\\n##### Install step\\n\\nDuring the first step, we launch a first deployment of the `Lambda` stack.\\nAt this step, the `ParamStore` stack does not exist, so no optional properties are passed.\\n\\n```ts title=\\"src/orbits/hello-agent.ts\\"\\nasync defineInstall() {\\n    await this.do(\'firstDeployLambda\', this.constructLambdaAgent());\\n}\\n\\nconstructLambdaAgent() {\\n    return new LambdaAgent().setArgument({\\n        stackName: \'lambda\',\\n        awsProfileName: this.argument.accountB.profile,\\n        stackProps: {\\n            env: {\\n                region: this.argument.region,\\n                account: this.argument.accountB.id,\\n            },\\n        },\\n    });\\n}\\n```\\n\\n##### Update step\\n\\nWhen updating the agent, we deploy both the `Param` and `Lambda` stack.\\n\\n```ts title=\\"src/orbits/hello-agent.ts\\"\\nasync defineUpdate() {\\n    const lambdaAgent = this.constructLambdaAgent();\\n\\n    const lambdaOutput = await this.do(\'getLambdaOutput\', () => {\\n        return lambdaAgent.getAgentOutput();\\n    });\\n\\n    const paramOutput = await this.do(\\n        \'updateParam\',\\n        this.constructParamAgent(lambdaOutput)\\n    );\\n\\n    await this.do(\'updateLambda\', this.constructLambdaAgent(paramOutput));\\n}\\n```\\n\\n`ParamAgent` consumes the output of `LambdaAgent` and vice versa.\\nAs a consequence, we need to refine the constructs methods.\\n\\n```ts title=\\"src/orbits/hello-agent.ts\\"\\nconstructLambdaAgent(paramOutput?: ParamAgent[\'IOutput\']) {\\n    return new LambdaAgent().setArgument({\\n        stackName: \'lambda\',\\n        awsProfileName: this.argument.accountB.profile,\\n        stackProps: {\\n            accountARoleArn: paramOutput?.roleArn,\\n            parameterArn: paramOutput?.paramArn,\\n            env: {\\n                region: this.argument.region,\\n                account: this.argument.accountB.id,\\n            },\\n        },\\n    });\\n}\\n\\nconstructParamAgent(lambdaOutput?: LambdaAgent[\'IOutput\']) {\\n    return new ParamAgent().setArgument({\\n        stackName: \'param\',\\n        awsProfileName: this.argument.accountA.profile,\\n        stackProps: {\\n            accountBId: this.argument.accountB.id,\\n            accountBRoleArn: lambdaOutput.roleArn,\\n            env: {\\n                region: this.argument.region,\\n                account: this.argument.accountA.id,\\n            },\\n        },\\n    });\\n}\\n```\\n\\n#### Uninstall step\\n\\nTo uninstall, we uninstall both the `Lambda` and `ParamStore` stacks.\\n\\n```ts title=\\"src/orbits/hello-agent.ts\\"\\nasync defineUninstall() {\\n    await this.do(\\n        \'uninstallLambda\',\\n        this.constructLambdaAgent().setCommand(\'Uninstall\')\\n    );\\n    await this.do(\\n        \'uninstallParam\',\\n        this.constructParamAgent().setCommand(\'Uninstall\')\\n    );\\n}\\n```\\n\\n### Deployment\\n\\nThe entire cross-account deployment happens with a single command:\\n\\n```bash\\nexport $(cat .env | xargs)\\nexport ORBITS_DB__MONGO__URL=your-mongo-url\\nnpx tsx src/orbits/orbi.ts\\n```\\n\\nThis orchestrates:\\n\\n1. Parameter deployment in Account A\\n2. Cross-account IAM policy setup\\n3. Lambda function deployment in Account B\\n4. All necessary permissions and configurations\\n\\n#### Verification\\n\\nAfter deployment, you can test the Lambda function in Account B. It will successfully retrieve the parameter from Account A, demonstrating seamless cross-account access.\\n\\nThe Lambda logs will show:\\n\\n```\\nParam: hello-world\\n```\\n\\n### Cleanup\\n\\nTo remove all deployed resources from both accounts:\\n\\n```bash\\nexport HELLO_COMMAND=uninstall\\nnpx tsx src/orbits/orbi.ts\\n```\\n\\n:::warning\\nThis will permanently delete all resources created by this example. Make sure you want to remove everything before running this command.\\n:::\\n\\n## Why This Matters\\n\\nThis example might seem simple, but it represents a fundamental gain in how we think about multi-account architectures. Instead of treating cross-account access as an exception requiring special handling, orbits makes it a first-class citizen of your infrastructure-as-code workflow. It allows to completely automate cross-account resources definition.\\n\\n### Key Benefits\\n\\n- **Declarative Cross-Account Resources:** Reference any resource from any account without manual coordination.\\n- **Automatic Permission Management:** IAM policies and resource policies are handled automatically.\\n- **Consistent Deployment Experience:** Multi-account deployments feel the same as single-account ones.\\n- **Simplified Maintenance:** Updates and changes don\'t require manual ARN extraction and policy coordination.\\n\\n## Looking Forward\\n\\nCross-account resource management shouldn\'t be a second-class citizen in your infrastructure-as-code workflow. Tools like orbits point toward a future where account boundaries enhance security without sacrificing developer experience.\\n\\nIf you\'re building multi-account architectures, I encourage you to try this example and see how much simpler cross-account resource management can be. The days of manual ARN extraction and policy coordination don\'t have to be permanent fixtures of AWS multi-account architectures.\\n\\n---\\n\\n_Ready to try it yourself? The complete example code and setup instructions are available in the repository. Give it a spin and share your experience with cross-account resource management._"},{"id":"manifesto","metadata":{"permalink":"/blog/manifesto","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2025-06-04-manifesto.md","source":"@site/blog/2025-06-04-manifesto.md","title":"Infra is code","description":"Infra is code!","date":"2025-06-04T00:00:00.000Z","tags":[{"inline":false,"label":"Manifesto","permalink":"/blog/tags/manifesto"},{"inline":false,"label":"OrbiTS","permalink":"/blog/tags/orbits","description":"Posts related to OrbiTS"}],"readingTime":2.81,"hasTruncateMarker":true,"authors":[{"name":"Louis Dussarps","title":"CEO @ Webcapsule","url":"https://github.com/louisdussarps","page":{"permalink":"/blog/authors/louis"},"socials":{"linkedin":"https://www.linkedin.com/in/louisdussarps/","github":"https://github.com/louisdussarps"},"imageURL":"/img/authors/louis.png","key":"louis"},{"name":"Lo\xefc D\xe9champs","title":"CTO @ Webcapsule","url":"https://github.com/ldechamps","page":{"permalink":"/blog/authors/loic"},"socials":{"linkedin":"https://www.linkedin.com/in/loicdechamps/","github":"https://github.com/ldechamps"},"imageURL":"/img/authors/loic.png","key":"loic"},{"name":"Arthur Rouzoul","title":"COO @ Webcapsule","url":"https://linkedin.com/in/arthurrouzoul","page":{"permalink":"/blog/authors/arthur"},"socials":{"linkedin":"https://www.linkedin.com/in/arthurrouzoul/","github":"https://github.com/Grouzoul"},"imageURL":"/img/authors/arthur.png","key":"arthur"},{"name":"Tom Marcuzzi","title":"Head of engineering @ Webcapsule","url":"https://linkedin.com/in/tom-marcuzzi","page":{"permalink":"/blog/authors/tom"},"socials":{"linkedin":"https://www.linkedin.com/in/tommarcuzzi/","github":"https://github.com/tommarcuzzi"},"imageURL":"/img/authors/tom.png","key":"tom"},{"name":"Sofia Chakir","title":"Head of cybersecurity @ Webcapsule","url":"https://linkedin.com/in/sofia-chakir","page":{"permalink":"/blog/authors/sofia"},"socials":{"linkedin":"https://www.linkedin.com/in/sofiachakir/","github":"https://github.com/sofiachakir"},"imageURL":"/img/authors/sofia.png","key":"sofia"}],"frontMatter":{"slug":"manifesto","title":"Infra is code","authors":["louis","loic","arthur","tom","sofia"],"tags":["manifesto","orbits"]},"unlisted":false,"prevItem":{"title":"Solving cross-account resources for AWS CDK","permalink":"/blog/cross-account-cdk"}},"content":"_Infra is code!_\\nAt first glance, this slogan might be the most stupid one ever read for a long time \u2014 if not on the entire planet, then at least in the web sphere. Yes, infrastructure has always been code: from the Ubuntu web server to the Cockroach database, it is nothing but code controlled by code. But if the Ops field has progressively shifted towards the notion of Infrastructure as Code, it is precisely because there is a substantial difference: the DevOps domain is better formalized as a description of reproducible artifacts rather than as a prescription of successive commands to execute.\\nThus, boldly displaying this slogan _Infra is code!_ on any article should make any somewhat experienced DevOps practitioner pause.\\n\\n\x3c!-- truncate --\x3e\\n\\nYet, friend reading these lines, don\u2019t go away so quickly! Haven\u2019t you already felt that while DevOps improved developers\u2019 lives with democratization of virtualization, convergence of interfaces, and unprecedented deployment speed, infrastructure itself remained, tucked away in some Git annex, a poor relative of computer code \u2014 difficult to edit, inflexible, and slow to test?\\nThe popular wisdom among developers seems to say: the less you touch infrastructure, the better off you are.\\nWith this, tirelessly, we arrive at a state-of-the-art where:\\n\\n- every project [restarts infrastructure work](https://www.reddit.com/r/devops/comments/1l8dsax/whats_eating_up_most_of_your_time_as_a_devops/) as if its neighbor didn\u2019t exist\\n- building a service stack remains a patchwork, a [conglomerate of loosely connected elements](https://www.tandfonline.com/doi/full/10.1080/17530350.2023.2229347)\\n- it is difficult, [without manual intervention, to redeploy an app from scratch on a new environment](https://insights.sei.cmu.edu/documents/576/2019_019_001_539335.pdf).\\n- apps are [hardly portable from one cloud to another](https://theses.hal.science/tel-02798770/file/90479_BRABRA_2020_archivage-4.pdf) \u2014 and the question of sovereignty is, out of frustration, abandoned.\\n\\nFinally, all in all, a large part of DevOps activity remains manual, and the trust chain in the system relies on a chain of responsibility and a comprehensive understanding of the system by a few operators in the team (which is positive) rather than on appropriate tooling (which is disappointing because, as system complexity grows, [relying solely on knowledge leads to rigid systems](https://link.springer.com/chapter/10.1007/978-3-319-74183-3_4)).\\n\\nConsequently, we unanimously demand that infrastructure specifications have the same rights and level of citizenship as any other piece of code in the stack.\\n\\nA demand that could remain dead letter if it were not accompanied by two recommendations:\\n\\n- orchestrators offer infrastructure an opportunity for liberation that it can seize to obtain its citizenship rights. The engineering platform movement has made a strong commitment in this direction and orchestration must be at the center of efforts.\\n\\n- increasingly, infrastructure benefits from being written in standard code: CDKs bear witness to the direction to follow. This allows a convergence of best practices between infrastructure and code.\\n\\nThus, IaC must be enhanced, orchestrated, and managed \u2014 as much as possible through standard code.\\nWe began working under these assumptions three years ago, and it has allowed us to build numerous engineering platforms since then. As we found nothing that met our criteria, we built our own orchestration framework: OrbiTS (aka Orbi.ts).\\nIt is now mature enough to fly on its own: since freedom is not won alone, we present it today to the community, hoping it can help build infrastructures and deployment pipelines that are more flexible, more robust, and more sovereign."}]}}')}}]);